%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}


\title{cmc}
\date{May 29, 2020}
\release{0.1.0}
\author{Daniel Helm}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


This python package is developed within the project \sphinxhref{https://www.vhh-project.eu/}{Visual History of the Holocaust} %
\begin{footnote}[1]\sphinxAtStartFootnote
\sphinxurl{https://www.vhh-project.eu/}
%
\end{footnote} (VHH) started in Januray 2019.
The major objective of this package is to provide interfaces and functions to classify image sequences
(shots) in one out the four classes: Extreme Long Shot (ELS), Long Shot (LS), Medium Shot (MS) or Close\sphinxhyphen{}Up shot (CU).
Those classes are the most significant cinematographic camera settings and represent the distance between an subject
and the camera.

This software package is installable and designed to reuse it in customized applications such as the \sphinxhref{https://github.com/dahe-cvl/vhh\_core}{vhh\_core} %
\begin{footnote}[2]\sphinxAtStartFootnote
\sphinxurl{https://github.com/dahe-cvl/vhh\_core}
%
\end{footnote} package. This
module represents the main controller in the context of the VHH project.

This documentation provides an API description of all classes, modules and member functions as well as
the required setup descriptions.


\chapter{Methodology}
\label{\detokenize{index:methodology}}

\chapter{Package Overview}
\label{\detokenize{index:package-overview}}
The following list give an overview of the folder structure of this python repository:

\sphinxstyleemphasis{name of repository}: vhh\_stc
\begin{itemize}
\item {} 
\sphinxstylestrong{ApiSphinxDocumentation/}: includes all files to generate the documentation as well as the created documentations (html, pdf)

\item {} 
\sphinxstylestrong{config/}: this folder includes the required configuration file

\item {} 
\sphinxstylestrong{stc/}: this folder represents the shot\sphinxhyphen{}type\sphinxhyphen{}classification module and builds the main part of this repository

\item {} 
\sphinxstylestrong{Demo/}: this folder includes a demo script to demonstrate how the package have to be used in customized applications

\item {} 
\sphinxstylestrong{Develop/}: includes scripts to train and evaluate the pytorch models. Furthermore, a script is included to create the package documentation (pdf, html)

\item {} 
\sphinxstylestrong{README.md}: this file gives a brief description of this repository (e.g. link to this documentation)

\item {} 
\sphinxstylestrong{requirements.txt}: this file holds all python lib dependencies and is needed to install the package in your own virtual environment

\item {} 
\sphinxstylestrong{setup.py}: this script is needed to install the stc package in your own virtual environment

\end{itemize}


\chapter{Setup  instructions}
\label{\detokenize{index:setup-instructions}}
This package includes a setup.py script and a requirements.txt file which are needed to install this package for custom applications.
The following instructions have to be done to used this library in your own application:

Requirements:
\begin{itemize}
\item {} 
Ubuntu 18.04 LTS

\item {} 
CUDA 10.1 + cuDNN

\item {} 
python version 3.6.x

\end{itemize}

Create a virtual environment:
\begin{itemize}
\item {} 
create a folder to a specified path (e.g. /xxx/vhh\_stc/)

\item {} 
python3 \sphinxhyphen{}m venv /xxx/vhh\_stc/

\end{itemize}

Activate the environment:
\begin{itemize}
\item {} 
source /xxx/vhh\_stc/bin/activate

\end{itemize}

Checkout vhh\_stc repository to a specified folder:
\begin{itemize}
\item {} 
git clone \sphinxurl{https://github.com/dahe-cvl/vhh\_stc}

\end{itemize}

Install the stc package and all dependencies:
\begin{itemize}
\item {} 
change to the root directory of the repository (includes setup.py)

\item {} 
python setup.py install

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
You can check the success of the installation by using the commend \sphinxstyleemphasis{pip list}. This command should give you a list with all installed python packages and it should include \sphinxstyleemphasis{vhh\_stc}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Currently there is an issue in the \sphinxstyleemphasis{setup.py} script. Therefore the pytorch libraries have to be installed manually by running the following command:
\sphinxstyleemphasis{pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 \sphinxhyphen{}f https://download.pytorch.org/whl/torch\_stable.html}
\end{sphinxadmonition}


\chapter{API Description}
\label{\detokenize{index:api-description}}
This section gives an overview of all classes and modules in \sphinxstyleemphasis{cmc} as well as an code description.


\section{Configuration class}
\label{\detokenize{Configuration:configuration-class}}\label{\detokenize{Configuration::doc}}\index{Configuration (class in cmc.Configuration)@\spxentry{Configuration}\spxextra{class in cmc.Configuration}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Configuration:cmc.Configuration.Configuration}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{cmc.Configuration.}}\sphinxbfcode{\sphinxupquote{Configuration}}}{\emph{\DUrole{n}{config\_file}\DUrole{p}{:} \DUrole{n}{str}}}{}
Bases: \sphinxcode{\sphinxupquote{object}}

This class is needed to read the configuration parameters specified in the configuration.yaml file.
The instance of the class is holding all parameters during runtime.

\begin{sphinxadmonition}{note}{Note:}
e.g. ./config/config\_vhh\_test.yaml
\begin{quote}

the yaml file is separated in multiple sections
config{[}‘Development’{]}
config{[}‘PreProcessing’{]}
config{[}‘CmcCore’{]}
config{[}‘Evaluation’{]}

whereas each section should hold related and meaningful parameters.
\end{quote}
\end{sphinxadmonition}
\index{loadConfig() (cmc.Configuration.Configuration method)@\spxentry{loadConfig()}\spxextra{cmc.Configuration.Configuration method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{Configuration:cmc.Configuration.Configuration.loadConfig}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{loadConfig}}}{}{}
Method to load configurables from the specified configuration file

\end{fulllineitems}


\end{fulllineitems}



\section{CMC class}
\label{\detokenize{CMC:cmc-class}}\label{\detokenize{CMC::doc}}\index{CMC (class in cmc.CMC)@\spxentry{CMC}\spxextra{class in cmc.CMC}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{CMC:cmc.CMC.CMC}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{cmc.CMC.}}\sphinxbfcode{\sphinxupquote{CMC}}}{\emph{\DUrole{n}{config\_file}\DUrole{p}{:} \DUrole{n}{str}}}{}
Bases: \sphinxcode{\sphinxupquote{object}}

Main class of camera movements classification (cmc) package.
\index{exportCmcResults() (cmc.CMC.CMC method)@\spxentry{exportCmcResults()}\spxextra{cmc.CMC.CMC method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{CMC:cmc.CMC.CMC.exportCmcResults}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{exportCmcResults}}}{\emph{\DUrole{n}{fName}}, \emph{\DUrole{n}{cmc\_results\_np}\DUrole{p}{:} \DUrole{n}{numpy.ndarray}}}{}
Method to export cmc results as csv file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{fName}} \textendash{} {[}required{]} name of result file.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cmc\_results\_np}} \textendash{} numpy array holding the camera movements classification predictions for each shot of a movie.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{loadSbdResults() (cmc.CMC.CMC method)@\spxentry{loadSbdResults()}\spxextra{cmc.CMC.CMC method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{CMC:cmc.CMC.CMC.loadSbdResults}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{loadSbdResults}}}{\emph{\DUrole{n}{sbd\_results\_path}}}{}
Method for loading shot boundary detection results as numpy array

\begin{sphinxadmonition}{note}{Note:}
Only used in debug\_mode.
\end{sphinxadmonition}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{sbd\_results\_path}} \textendash{} {[}required{]} path to results file of shot boundary detection module (vhh\_sbd)

\item[{Returns}] \leavevmode
numpy array holding list of detected shots.

\end{description}\end{quote}

\end{fulllineitems}

\index{runOnSingleVideo() (cmc.CMC.CMC method)@\spxentry{runOnSingleVideo()}\spxextra{cmc.CMC.CMC method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{CMC:cmc.CMC.CMC.runOnSingleVideo}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{runOnSingleVideo}}}{\emph{\DUrole{n}{shots\_per\_vid\_np}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{max\_recall\_id}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 1}}}{}
Method to run cmc classification on specified video.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{shots\_per\_vid\_np}} \textendash{} {[}required{]} numpy array representing all detected shots in a video
(e.g. sid | movie\_name | start | end )

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_recall\_id}} \textendash{} {[}required{]} integer value holding unique video id from VHH MMSI system

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{OpticalFlow class}
\label{\detokenize{OpticalFlow:opticalflow-class}}\label{\detokenize{OpticalFlow::doc}}\index{OpticalFlow (class in cmc.OpticalFlow)@\spxentry{OpticalFlow}\spxextra{class in cmc.OpticalFlow}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{OpticalFlow:cmc.OpticalFlow.OpticalFlow}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{cmc.OpticalFlow.}}\sphinxbfcode{\sphinxupquote{OpticalFlow}}}{\emph{video\_frames=None}, \emph{fPath=\textquotesingle{}\textquotesingle{}}, \emph{debug\_path=\textquotesingle{}\textquotesingle{}}, \emph{sf=0}, \emph{ef=1}, \emph{mode=0}, \emph{pan\_classifier=\textless{}cmc.OpticalFlow.AngleClassifier object\textgreater{}}, \emph{tilt\_classifier=\textless{}cmc.OpticalFlow.AngleClassifier object\textgreater{}}, \emph{sensitivity=20}, \emph{specificity=3}, \emph{border=50}, \emph{number\_of\_features=100}, \emph{angle\_diff\_limit=20}, \emph{config=None}}{}
Bases: \sphinxcode{\sphinxupquote{object}}

This class is used for optical flow calculation.
\index{\_\_init\_\_() (cmc.OpticalFlow.OpticalFlow method)@\spxentry{\_\_init\_\_()}\spxextra{cmc.OpticalFlow.OpticalFlow method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{OpticalFlow:cmc.OpticalFlow.OpticalFlow.__init__}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{video\_frames=None}, \emph{fPath=\textquotesingle{}\textquotesingle{}}, \emph{debug\_path=\textquotesingle{}\textquotesingle{}}, \emph{sf=0}, \emph{ef=1}, \emph{mode=0}, \emph{pan\_classifier=\textless{}cmc.OpticalFlow.AngleClassifier object\textgreater{}}, \emph{tilt\_classifier=\textless{}cmc.OpticalFlow.AngleClassifier object\textgreater{}}, \emph{sensitivity=20}, \emph{specificity=3}, \emph{border=50}, \emph{number\_of\_features=100}, \emph{angle\_diff\_limit=20}, \emph{config=None}}{}
Constructor.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{video\_frames}} \textendash{} This parameter holds a valid numpy array representing a range of frames (e.g. NxWxHxchannels).

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{fPath}} \textendash{} This parameter holds a valid path consisting of the absolute path and the correct video name.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{debug\_path}} \textendash{} This parameter specifies a valid path to store results in debug mode.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sf}} \textendash{} This parameter represents the starting frame index.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{ef}} \textendash{} This parameter represents the ending frame index.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{mode}} \textendash{} This parameter represents runtime mode (e.g. DEBUG\_MODE=1 or SAVE\_MODE=2).

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{pan\_classifier}} \textendash{} This parameter holds a valid object of class type AngleClassifier.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tilt\_classifier}} \textendash{} This parameter holds a valid object of class type AngleClassifier.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sensitivity}} \textendash{} This parameter is used to configure the optical flow algorithm.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{specificity}} \textendash{} This parameter is used to configure the optical flow algorithm.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{border}} \textendash{} This parameter is used to configure the optical flow algorithm.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{number\_of\_features}} \textendash{} This parameter is used to configure the optical flow algorithm.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{angle\_diff\_limit}} \textendash{} This parameter is used to configure the optical flow algorithm.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{config}} \textendash{} 

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{optical\_flow() (cmc.OpticalFlow.OpticalFlow method)@\spxentry{optical\_flow()}\spxextra{cmc.OpticalFlow.OpticalFlow method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{OpticalFlow:cmc.OpticalFlow.OpticalFlow.optical_flow}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{optical\_flow}}}{\emph{\DUrole{n}{prev\_frame}}, \emph{\DUrole{n}{prev\_feat}}, \emph{\DUrole{n}{curr\_frame}}}{}
This method is used to calculate the optical flow between two consecutive frames.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{prev\_frame}} \textendash{} This parameter must hold a valid numpy frame (previous).

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{prev\_feat}} \textendash{} This parameter must hold valid features of the previous frame.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{curr\_frame}} \textendash{} This parameter must hold a valid numpy frame (current).

\end{itemize}

\item[{Returns}] \leavevmode
This method returns two arrays including the features of the previous frame as well as of the current frame.

\end{description}\end{quote}

\end{fulllineitems}

\index{run() (cmc.OpticalFlow.OpticalFlow method)@\spxentry{run()}\spxextra{cmc.OpticalFlow.OpticalFlow method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{OpticalFlow:cmc.OpticalFlow.OpticalFlow.run}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{run}}}{}{}
This method is used to run the optical flow calculation process.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
This method returns a separate list for each movement class and holds the predicted frame ranges of both.

\end{description}\end{quote}

\end{fulllineitems}

\index{run\_eval() (cmc.OpticalFlow.OpticalFlow method)@\spxentry{run\_eval()}\spxextra{cmc.OpticalFlow.OpticalFlow method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{OpticalFlow:cmc.OpticalFlow.OpticalFlow.run_eval}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{run\_eval}}}{}{}
This method is used to run the optical flow calculation to evaluate specified videos.

\end{fulllineitems}

\index{run\_manual\_evaluation() (cmc.OpticalFlow.OpticalFlow method)@\spxentry{run\_manual\_evaluation()}\spxextra{cmc.OpticalFlow.OpticalFlow method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{OpticalFlow:cmc.OpticalFlow.OpticalFlow.run_manual_evaluation}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{run\_manual\_evaluation}}}{}{}
This method is used to run optical flow process in DEBUG mode. A valid X\sphinxhyphen{}Server is needed to visualize the frame player.

\end{fulllineitems}


\end{fulllineitems}



\section{PreProcessing class}
\label{\detokenize{PreProcessing:preprocessing-class}}\label{\detokenize{PreProcessing::doc}}\index{PreProcessing (class in cmc.PreProcessing)@\spxentry{PreProcessing}\spxextra{class in cmc.PreProcessing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{PreProcessing:cmc.PreProcessing.PreProcessing}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{cmc.PreProcessing.}}\sphinxbfcode{\sphinxupquote{PreProcessing}}}{\emph{\DUrole{n}{config\_instance}\DUrole{p}{:} \DUrole{n}{{\hyperref[\detokenize{Configuration:cmc.Configuration.Configuration}]{\sphinxcrossref{cmc.Configuration.Configuration}}}}}}{}
Bases: \sphinxcode{\sphinxupquote{object}}

This class is used to pre\sphinxhyphen{}process frames.
\index{applyTransformOnImg() (cmc.PreProcessing.PreProcessing method)@\spxentry{applyTransformOnImg()}\spxextra{cmc.PreProcessing.PreProcessing method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{PreProcessing:cmc.PreProcessing.PreProcessing.applyTransformOnImg}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{applyTransformOnImg}}}{\emph{\DUrole{n}{image}\DUrole{p}{:} \DUrole{n}{numpy.ndarray}}}{{ $\rightarrow$ numpy.ndarray}}
This method is used to apply the configured pre\sphinxhyphen{}processing methods on a numpy frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{image}} \textendash{} This parameter must hold a valid numpy image (WxHxC).

\item[{Returns}] \leavevmode
This methods returns the preprocessed numpy image.

\end{description}\end{quote}

\end{fulllineitems}

\index{convertRGB2Gray() (cmc.PreProcessing.PreProcessing method)@\spxentry{convertRGB2Gray()}\spxextra{cmc.PreProcessing.PreProcessing method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{PreProcessing:cmc.PreProcessing.PreProcessing.convertRGB2Gray}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{convertRGB2Gray}}}{\emph{\DUrole{n}{img}\DUrole{p}{:} \DUrole{n}{numpy.ndarray}}}{}
This method is used to convert a RBG numpy image to a grayscale image.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{img}} \textendash{} This parameter must hold a valid numpy image.

\item[{Returns}] \leavevmode
This method returns a grayscale image (WxHx1).

\end{description}\end{quote}

\end{fulllineitems}

\index{crop() (cmc.PreProcessing.PreProcessing method)@\spxentry{crop()}\spxextra{cmc.PreProcessing.PreProcessing method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{PreProcessing:cmc.PreProcessing.PreProcessing.crop}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{crop}}}{\emph{\DUrole{n}{img}\DUrole{p}{:} \DUrole{n}{numpy.ndarray}}, \emph{\DUrole{n}{dim}\DUrole{p}{:} \DUrole{n}{tuple}}}{}
This method is used to crop a specified region of interest from a given image.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{img}} \textendash{} This parameter must hold a valid numpy image.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{dim}} \textendash{} This parameter must hold a valid tuple including the crop dimensions.

\end{itemize}

\item[{Returns}] \leavevmode
This method returns the cropped image.

\end{description}\end{quote}

\end{fulllineitems}

\index{resize() (cmc.PreProcessing.PreProcessing method)@\spxentry{resize()}\spxextra{cmc.PreProcessing.PreProcessing method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{PreProcessing:cmc.PreProcessing.PreProcessing.resize}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{resize}}}{\emph{\DUrole{n}{img}\DUrole{p}{:} \DUrole{n}{numpy.ndarray}}, \emph{\DUrole{n}{dim}\DUrole{p}{:} \DUrole{n}{tuple}}}{}
This method is used to resize a image.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{img}} \textendash{} This parameter must hold a valid numpy image.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{dim}} \textendash{} This parameter must hold a valid tuple including the resize dimensions.

\end{itemize}

\item[{Returns}] \leavevmode
This method returns the resized image.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\section{References}
\label{\detokenize{index:references}}


\renewcommand{\indexname}{Index}
\printindex
\end{document}